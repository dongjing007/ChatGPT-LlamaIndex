{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32qJZxmOeXBF"
      },
      "source": [
        "### **安装环境依赖**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "udFz2NpdeXRw"
      },
      "outputs": [],
      "source": [
        "!pip install llama-index\n",
        "!pip install langchain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Idl_Ufr3fMhg"
      },
      "source": [
        "### **导入所需包**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nuyAKDcyea6-"
      },
      "outputs": [],
      "source": [
        "from langchain import OpenAI\n",
        "from llama_index import SimpleDirectoryReader,GPTSimpleVectorIndex, PromptHelper, LLMPredictor, ServiceContext\n",
        "import sys\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgSzM0-zhG6_"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnqSqoX4fHZV"
      },
      "source": [
        "### **设置OPENAI_API_KEY**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j6yx6eHDia8G"
      },
      "outputs": [],
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = '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'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aw76OQ6DfhxH"
      },
      "source": [
        "### **construct_index函数：导入知识库，生成index.json**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MmoQ0jSRZXhj"
      },
      "outputs": [],
      "source": [
        "\n",
        "def construct_index(directory_path):\n",
        "  # 設置最大可輸入token數\n",
        "  max_input_size = 4096\n",
        "  # 設置輸出token數\n",
        "  num_outputs = 256\n",
        "  # 設置生成embedding時滑窗大小\n",
        "  max_chunk_overlap = 20\n",
        "  # 設置塊大小\n",
        "  chunk_size_limit = 100\n",
        "  \n",
        "  # 設置prompt提示語\n",
        "  prompt_helper = PromptHelper(max_input_size, num_outputs, max_chunk_overlap, chunk_size_limit=chunk_size_limit)\n",
        "\n",
        "  # 設置LLM，temperature值越小，返回結果越精準\n",
        "  llm_predictor = LLMPredictor(llm=OpenAI(temperature=0, model_name=\"gpt-3.5-turbo\", max_tokens=num_outputs))\n",
        "  \n",
        "  documents = SimpleDirectoryReader(directory_path).load_data()\n",
        "  \n",
        "  service_context = ServiceContext.from_defaults(llm_predictor=llm_predictor, prompt_helper=prompt_helper)\n",
        "  index = GPTSimpleVectorIndex.from_documents(documents, service_context=service_context)\n",
        "  \n",
        "  index.save_to_disk('index.json')\n",
        "  \n",
        "  return index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYJXTIuSf7Ix"
      },
      "source": [
        "### **ask_bot函数：实现加载index.json，并桥接ChatGPT会话**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GW1tTw2VeWgS"
      },
      "outputs": [],
      "source": [
        "def ask_bot(input_index = 'index.json'):\n",
        "  index = GPTSimpleVectorIndex.load_from_disk(input_index)\n",
        "  while True:\n",
        "    query = input('你好，請問需要提供什麼幫助?   \\n')\n",
        "    response = index.query(query, response_mode=\"compact\")\n",
        "    print (\"\\nChat-Bot says: \\n\\n\" + response.response + \"\\n\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fpP4OXGgPfm"
      },
      "source": [
        "### **下载原始知识库到本地**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oAYkSPzqOy0C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7542c1f-3978-4840-bdb1-534d6cd4603c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'context_data' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/dongjing007/context_data.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8AQbZqQdgY3w"
      },
      "source": [
        "### **调用方法，生成知识库对应的index.json**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gM00_PPYO2PB"
      },
      "outputs": [],
      "source": [
        "index = construct_index(\"context_data/data\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcp_un4rgi3_"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7SBZcdzglLF"
      },
      "source": [
        "### **加载index.json，桥接ChatGPT，进行会话**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "id": "wOWoWflrP2pO",
        "outputId": "661966a6-4a54-4101-e402-6233fa409539"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-bd47e40bea98>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mask_bot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'index.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-e7ddc40ff84f>\u001b[0m in \u001b[0;36mask_bot\u001b[0;34m(input_index)\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGPTSimpleVectorIndex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from_disk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'What do you want to ask the bot?   \\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"compact\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nBot says: \\n\\n\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\\n\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ],
      "source": [
        "ask_bot('index.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OxfT37qTQVOx"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}